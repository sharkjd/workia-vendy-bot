from langchain_core.messages import SystemMessage
from models_config import get_llm_with_tools
from agent_config import get_model_for_agent
from . import prompts

def change_process_node(state):
    """
    Agent zodpov캩dn칳 za ad-hoc zm캩ny a dotazy na data.
    C칤l: Umo쬹it kandid치tovi upravit jakoukoli 캜치st profilu kdykoliv.
    """
    candidate = state.get("candidate_data", {})
    row_id = state.get("row_id")
    
    # 1. Napln칤me prompt v코emi prom캩nn칳mi, aby Vendy mohla o datech i mluvit
    # Mus칤me pokr칳t v코e, co jsme si definovali v CHANGE_PROCESS_PROMPT
    instructions = prompts.CHANGE_PROCESS_PROMPT.format(
        persona=prompts.BASE_VENDY_PERSONA,
        row_id=row_id,
        full_name=candidate.get("full_name", "N/A"),
        email=candidate.get("email", "N/A"),
        web_city=candidate.get("web_city", "N/A"),
        web_position=candidate.get("web_position", "N/A"),
        web_availability=candidate.get("web_availability", "N/A"),
        last_position_detail=candidate.get("last_position_detail", "N/A"),
        last_salary=candidate.get("last_salary", "N/A"),
        expected_salary=candidate.get("expected_salary", "N/A")
    )
    
    # 2. O코et콏en칤 historie zpr치v (Guardrail proti 400 INVALID_ARGUMENT)
    # Vezmeme posledn칤ch 10 zpr치v a zajist칤me, 쬰 za캜칤n치me zpr치vou od 캜lov캩ka
    messages = state["messages"]
    recent_messages = messages[-10:]
    
    while recent_messages and recent_messages[0].type not in ["human", "system"]:
        recent_messages.pop(0)
        
    # Pokud by po vy캜i코t캩n칤 nic nezbylo, vezmeme aspo켿 칰pln캩 posledn칤 zpr치vu
    if not recent_messages:
        recent_messages = messages[-1:]

    # 3. Dynamicky na캜teme model pro tohoto agenta z konfigurace
    model_name = get_model_for_agent("change_process")
    llm = get_llm_with_tools(model_name)
    print(f"游뱄 Agent 'change_process' pou쮂셨치 model: {model_name}")

    # 4. Vol치n칤 modelu
    response = llm.invoke([SystemMessage(content=instructions)] + recent_messages)
    
    return {"messages": [response]}